{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electronic-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled in this notebook.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from pymongo import MongoClient, ASCENDING, DESCENDING, HASHED\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_device():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        print(\"WARNING: For this notebook to perform best, \"\n",
    "              \"if possible, in the menu under `Runtime` -> \"\n",
    "              \"`Change runtime type.`  select `GPU` \")\n",
    "    else:\n",
    "        print(\"GPU is enabled in this notebook.\")\n",
    "    return device\n",
    "\n",
    "\n",
    "device = set_device()\n",
    "\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "settled-daily",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'userId_hashed'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = MongoClient()\n",
    "\n",
    "process_fibvid = conn.process_fibvid\n",
    "tweets_bert_tokens  = process_fibvid.tweets_bert_tokens\n",
    "tweets_bert  = process_fibvid.tweets_bert\n",
    "\n",
    "tweets_bert.create_index([('num_tokens', ASCENDING)])\n",
    "tweets_bert.create_index([('created', ASCENDING)])\n",
    "tweets_bert.create_index([('tweetId', HASHED)])\n",
    "tweets_bert.create_index([('userId', HASHED)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "primary-perfume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ee7c0751d743bea43d37d7668c78bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/299118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total = tweets_bert_tokens.count_documents({})\n",
    "\n",
    "\n",
    "def process(to_process, size, model=model, col=tweets_bert):\n",
    "    if len(to_process) == 0:\n",
    "        return []\n",
    "    in_data = {'input_ids': np.empty((len(to_process), size), dtype=np.int32),\n",
    "              'attention_mask': np.empty((len(to_process), size), dtype=np.int32),\n",
    "              'token_type_ids': np.empty((len(to_process), size), dtype=np.int32)}\n",
    "    for i, v in enumerate(to_process):\n",
    "        for k in in_data.keys():\n",
    "            in_data[k][i, :] = v[k]\n",
    "    with torch.no_grad():\n",
    "        for k in in_data.keys():\n",
    "                in_data[k] = torch.from_numpy(in_data[k]).to(device)\n",
    "        post = {k: v.cpu().numpy() for k, v in model(**in_data).items()}\n",
    "        to_save = []\n",
    "        for i, v in enumerate(to_process):\n",
    "            data = {'num_tokens': v['num_tokens'],\n",
    "                   'created': v['created'],\n",
    "                   'userId': v['userId'],\n",
    "                   'tweetId': v['tweetId']}\n",
    "            for k, v in post.items():\n",
    "                data[k] = v[i, ...].tolist()\n",
    "            to_save.append(data)\n",
    "            #del data['last_hidden_state']\n",
    "    return to_save\n",
    "\n",
    "to_process = []\n",
    "BATCH_SIZE = 128\n",
    "DB_BATCH_SIZE = 500\n",
    "current_size = -1\n",
    "db_batch = []\n",
    "\n",
    "\n",
    "with conn.start_session() as session: \n",
    "    for tweet in tqdm(tweets_bert_tokens.find(no_cursor_timeout=True, \n",
    "                                        session=session).sort([('num_tokens', DESCENDING)]), total=total):\n",
    "        if current_size != tweet['num_tokens']:\n",
    "            db_batch.extend(process(to_process, current_size))\n",
    "            to_process = []\n",
    "            current_size = tweet['num_tokens']\n",
    "        if len(to_process) == BATCH_SIZE:\n",
    "            db_batch.extend(process(to_process, current_size))\n",
    "            to_process = []\n",
    "        if len(db_batch) > DB_BATCH_SIZE:\n",
    "            tweets_bert.insert_many(db_batch)\n",
    "            db_batch = []\n",
    "        to_process.append(tweet)\n",
    "\n",
    "        \n",
    "db_batch.extend(process(to_process, current_size))\n",
    "if len(db_batch) > 0:\n",
    "    tweets_bert.insert_many(db_batch)\n",
    "    db_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3bbe25-421d-4458-9122-44c07542a51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
